The PI05 model is a direct port of the OpenPI implementation. 
This implementation follows the original OpenPI structure for compatibility. 
Original implementation: https://github.com/Physical-Intelligence/openpi
Loading model from: Grigorij/pi05_right-arm-grab-notebook
âœ“ Loaded state dict from model.safetensors
Warning: Could not remap state dict keys: Error(s) in loading state_dict for PI05Policy:
	Missing key(s) in state_dict: "model.paligemma_with_expert.paligemma.model.language_model.embed_tokens.weight", "model.paligemma_with_expert.gemma_expert.model.layers.0.input_layernorm.weight", "model.paligemma_with_expert.gemma_expert.model.layers.0.post_attention_layernorm.weight", "model.paligemma_with_expert.gemma_expert.model.layers.1.input_layernorm.weight", "model.paligemma_with_expert.gemma_expert.model.layers.1.post_attention_layernorm.weight", "model.paligemma_with_expert.gemma_expert.model.layers.2.input_layernorm.weight", "model.paligemma_with_expert.gemma_expert.model.layers.2.post_attention_layernorm.weight", "model.paligemma_with_expert.gemma_expert.model.layers.3.input_layernorm.weight", "model.paligemma_with_expert.gemma_expert.model.layers.3.post_attention_layernorm.weight", "model.paligemma_with_expert.gemma_expert.model.layers.4.input_layernorm.weight", "model.paligemma_with_expert.gemma_expert.model.layers.4.post_attention_layernorm.weight", "model.paligemma_with_expert.gemma_expert.model.layers.5.input_layernorm.weight", "model.paligemma_with_expert.gemma_expert.model.layers.5.post_attention_layernorm.weight", "model.paligemma_with_expert.gemma_expert.model.layers.6.input_layernorm.weight", "model.paligemma_with_expert.gemma_expert.model.layers.6.post_attention_layernorm.weight", "model.paligemma_with_expert.gemma_expert.model.layers.7.input_layernorm.weight", "model.paligemma_with_expert.gemma_expert.model.layers.7.post_attention_layernorm.weight", "model.paligemma_with_expert.gemma_expert.model.layers.8.input_layernorm.weight", "model.paligemma_with_expert.gemma_expert.model.layers.8.post_attention_layernorm.weight", "model.paligemma_with_expert.gemma_expert.model.layers.9.input_layernorm.weight", "model.paligemma_with_expert.gemma_expert.model.layers.9.post_attention_layernorm.weight", "model.paligemma_with_expert.gemma_expert.model.layers.10.input_layernorm.weight", "model.paligemma_with_expert.gemma_expert.model.layers.10.post_attention_layernorm.weight", "model.paligemma_with_expert.gemma_expert.model.layers.11.input_layernorm.weight", "model.paligemma_with_expert.gemma_expert.model.layers.11.post_attention_layernorm.weight", "model.paligemma_with_expert.gemma_expert.model.layers.12.input_layernorm.weight", "model.paligemma_with_expert.gemma_expert.model.layers.12.post_attention_layernorm.weight", "model.paligemma_with_expert.gemma_expert.model.layers.13.input_layernorm.weight", "model.paligemma_with_expert.gemma_expert.model.layers.13.post_attention_layernorm.weight", "model.paligemma_with_expert.gemma_expert.model.layers.14.input_layernorm.weight", "model.paligemma_with_expert.gemma_expert.model.layers.14.post_attention_layernorm.weight", "model.paligemma_with_expert.gemma_expert.model.layers.15.input_layernorm.weight", "model.paligemma_with_expert.gemma_expert.model.layers.15.post_attention_layernorm.weight", "model.paligemma_with_expert.gemma_expert.model.layers.16.input_layernorm.weight", "model.paligemma_with_expert.gemma_expert.model.layers.16.post_attention_layernorm.weight", "model.paligemma_with_expert.gemma_expert.model.layers.17.input_layernorm.weight", "model.paligemma_with_expert.gemma_expert.model.layers.17.post_attention_layernorm.weight", "model.paligemma_with_expert.gemma_expert.model.norm.weight". 
	Unexpected key(s) in state_dict: "model.paligemma_with_expert.gemma_expert.model.layers.0.input_layernorm.dense.bias", "model.paligemma_with_expert.gemma_expert.model.layers.0.input_layernorm.dense.weight", "model.paligemma_with_expert.gemma_expert.model.layers.0.post_attention_layernorm.dense.bias", "model.paligemma_with_expert.gemma_expert.model.layers.0.post_attention_layernorm.dense.weight", "model.paligemma_with_expert.gemma_expert.model.layers.1.input_layernorm.dense.bias", "model.paligemma_with_expert.gemma_expert.model.layers.1.input_layernorm.dense.weight", "model.paligemma_with_expert.gemma_expert.model.layers.1.post_attention_layernorm.dense.bias", "model.paligemma_with_expert.gemma_expert.model.layers.1.post_attention_layernorm.dense.weight", "model.paligemma_with_expert.gemma_expert.model.layers.2.input_layernorm.dense.bias", "model.paligemma_with_expert.gemma_expert.model.layers.2.input_layernorm.dense.weight", "model.paligemma_with_expert.gemma_expert.model.layers.2.post_attention_layernorm.dense.bias", "model.paligemma_with_expert.gemma_expert.model.layers.2.post_attention_layernorm.dense.weight", "model.paligemma_with_expert.gemma_expert.model.layers.3.input_layernorm.dense.bias", "model.paligemma_with_expert.gemma_expert.model.layers.3.input_layernorm.dense.weight", "model.paligemma_with_expert.gemma_expert.model.layers.3.post_attention_layernorm.dense.bias", "model.paligemma_with_expert.gemma_expert.model.layers.3.post_attention_layernorm.dense.weight", "model.paligemma_with_expert.gemma_expert.model.layers.4.input_layernorm.dense.bias", "model.paligemma_with_expert.gemma_expert.model.layers.4.input_layernorm.dense.weight", "model.paligemma_with_expert.gemma_expert.model.layers.4.post_attention_layernorm.dense.bias", "model.paligemma_with_expert.gemma_expert.model.layers.4.post_attention_layernorm.dense.weight", "model.paligemma_with_expert.gemma_expert.model.layers.5.input_layernorm.dense.bias", "model.paligemma_with_expert.gemma_expert.model.layers.5.input_layernorm.dense.weight", "model.paligemma_with_expert.gemma_expert.model.layers.5.post_attention_layernorm.dense.bias", "model.paligemma_with_expert.gemma_expert.model.layers.5.post_attention_layernorm.dense.weight", "model.paligemma_with_expert.gemma_expert.model.layers.6.input_layernorm.dense.bias", "model.paligemma_with_expert.gemma_expert.model.layers.6.input_layernorm.dense.weight", "model.paligemma_with_expert.gemma_expert.model.layers.6.post_attention_layernorm.dense.bias", "model.paligemma_with_expert.gemma_expert.model.layers.6.post_attention_layernorm.dense.weight", "model.paligemma_with_expert.gemma_expert.model.layers.7.input_layernorm.dense.bias", "model.paligemma_with_expert.gemma_expert.model.layers.7.input_layernorm.dense.weight", "model.paligemma_with_expert.gemma_expert.model.layers.7.post_attention_layernorm.dense.bias", "model.paligemma_with_expert.gemma_expert.model.layers.7.post_attention_layernorm.dense.weight", "model.paligemma_with_expert.gemma_expert.model.layers.8.input_layernorm.dense.bias", "model.paligemma_with_expert.gemma_expert.model.layers.8.input_layernorm.dense.weight", "model.paligemma_with_expert.gemma_expert.model.layers.8.post_attention_layernorm.dense.bias", "model.paligemma_with_expert.gemma_expert.model.layers.8.post_attention_layernorm.dense.weight", "model.paligemma_with_expert.gemma_expert.model.layers.9.input_layernorm.dense.bias", "model.paligemma_with_expert.gemma_expert.model.layers.9.input_layernorm.dense.weight", "model.paligemma_with_expert.gemma_expert.model.layers.9.post_attention_layernorm.dense.bias", "model.paligemma_with_expert.gemma_expert.model.layers.9.post_attention_layernorm.dense.weight", "model.paligemma_with_expert.gemma_expert.model.layers.10.input_layernorm.dense.bias", "model.paligemma_with_expert.gemma_expert.model.layers.10.input_layernorm.dense.weight", "model.paligemma_with_expert.gemma_expert.model.layers.10.post_attention_layernorm.dense.bias", "model.paligemma_with_expert.gemma_expert.model.layers.10.post_attention_layernorm.dense.weight", "model.paligemma_with_expert.gemma_expert.model.layers.11.input_layernorm.dense.bias", "model.paligemma_with_expert.gemma_expert.model.layers.11.input_layernorm.dense.weight", "model.paligemma_with_expert.gemma_expert.model.layers.11.post_attention_layernorm.dense.bias", "model.paligemma_with_expert.gemma_expert.model.layers.11.post_attention_layernorm.dense.weight", "model.paligemma_with_expert.gemma_expert.model.layers.12.input_layernorm.dense.bias", "model.paligemma_with_expert.gemma_expert.model.layers.12.input_layernorm.dense.weight", "model.paligemma_with_expert.gemma_expert.model.layers.12.post_attention_layernorm.dense.bias", "model.paligemma_with_expert.gemma_expert.model.layers.12.post_attention_layernorm.dense.weight", "model.paligemma_with_expert.gemma_expert.model.layers.13.input_layernorm.dense.bias", "model.paligemma_with_expert.gemma_expert.model.layers.13.input_layernorm.dense.weight", "model.paligemma_with_expert.gemma_expert.model.layers.13.post_attention_layernorm.dense.bias", "model.paligemma_with_expert.gemma_expert.model.layers.13.post_attention_layernorm.dense.weight", "model.paligemma_with_expert.gemma_expert.model.layers.14.input_layernorm.dense.bias", "model.paligemma_with_expert.gemma_expert.model.layers.14.input_layernorm.dense.weight", "model.paligemma_with_expert.gemma_expert.model.layers.14.post_attention_layernorm.dense.bias", "model.paligemma_with_expert.gemma_expert.model.layers.14.post_attention_layernorm.dense.weight", "model.paligemma_with_expert.gemma_expert.model.layers.15.input_layernorm.dense.bias", "model.paligemma_with_expert.gemma_expert.model.layers.15.input_layernorm.dense.weight", "model.paligemma_with_expert.gemma_expert.model.layers.15.post_attention_layernorm.dense.bias", "model.paligemma_with_expert.gemma_expert.model.layers.15.post_attention_layernorm.dense.weight", "model.paligemma_with_expert.gemma_expert.model.layers.16.input_layernorm.dense.bias", "model.paligemma_with_expert.gemma_expert.model.layers.16.input_layernorm.dense.weight", "model.paligemma_with_expert.gemma_expert.model.layers.16.post_attention_layernorm.dense.bias", "model.paligemma_with_expert.gemma_expert.model.layers.16.post_attention_layernorm.dense.weight", "model.paligemma_with_expert.gemma_expert.model.layers.17.input_layernorm.dense.bias", "model.paligemma_with_expert.gemma_expert.model.layers.17.input_layernorm.dense.weight", "model.paligemma_with_expert.gemma_expert.model.layers.17.post_attention_layernorm.dense.bias", "model.paligemma_with_expert.gemma_expert.model.layers.17.post_attention_layernorm.dense.weight", "model.paligemma_with_expert.gemma_expert.model.norm.dense.bias", "model.paligemma_with_expert.gemma_expert.model.norm.dense.weight". 
Task: Grab a notebook..
Joint states: [-2.606806755065918, -86.74496459960938, 98.1448745727539, 38.40367889404297, 90.76923370361328, 26.590330123901367]
